キー結論（超短縮）

推奨アプローチ：PixiJS v8 の WebGPURenderer をベースにして、GPU 側での「ストローク展開（stroke expansion）→ 三角形化 → フラグメントでSDF/AA処理」パイプラインを採る。これは近年の研究（GPU-friendly stroke expansion）で実用性が示されています。
PixiJS
arXiv

代替（より簡単）：CPU でパス→セグメント化→頂点バッファを作り、GPU で fill（頂点／フラグメントシェーダ）＆MSAA/シェーダAA を行う。WebGPU が使えるなら compute シェーダでストローク展開を高速化するのが理想。
WebGPU Fundamentals
arXiv

アンチエイリアス：SDF / MSDF（またはシェーダ内の距離ベース AA）で高品質を得る。MSDF 等はシャープな角も保持できます。
Red Blob Games
GitHub

なぜ WebGPU + GPU ストローク展開が良いか（根拠）

ストローク展開は「グローバルでコストの高い問題」だが、GPU の並列処理（compute shader）でほぼ線形時間に近い並列化が可能と最近の論文で示されています（GPU-friendly stroke expansion）。これにより、リアルタイムで巨大なパス・多数ブラシを扱えるようになります。
arXiv

Pixi v8 は WebGPU レンダラーを取り込んでおり、将来性・互換性・最適化の面で有利。まずは Pixi の WebGPURenderer を土台に作るのがコスパが高いです。
PixiJS
PixiJS

WebGPU 最適化の知見（バッファ管理、バインドグループ、compute→render のパイプライン、同期最小化）は 120Hz を目指す際に不可欠。
WebGPU Fundamentals
Google Codelabs

全体アーキテクチャ（高レベル）

Input layer（CPU）

ポインタ入力を受け取り「パス」データ（時間付き座標、圧力、傾き、ベジェ近似）を生成。

ポインタ点はイベントごとに小さなバッファに集積（coalescing）。毎フレームで GPU に送る単位を調整（例：16ms ごとやフレームごと）。

CPU → GPU 転送

生成したパスは GPU へ転送（WebGPU の storage buffer / vertex buffer）。

短時間のストロークは「動的頂点バッファ」に書き込み、リアルタイム描画に使用。

GPU Compute（Stroke Expansion）

Compute シェーダで「パス」→「アウトライン（ポリゴン）」に展開（論文のアルゴリズム）。各 path は並列で処理。結果はインデックス付き頂点バッファに格納。
arXiv

GPU Render（Triangle Fill + AA）

得られたポリゴンを通常のトライアングルで描画。フラグメントシェーダでは距離ベースの AA（SDF 的）やプロファイルベースのフェードで高品質なエッジを実現。

追加でペンのテクスチャ（ノイズ・毛羽）を合成することで豊かな筆致に。

Composite & Presentation

レイヤー毎に描画し、合成は premultiplied alpha で GPU 内で完結。ダブルバッファ／GPU fence を使い、120Hzのフレーム更新と GPU 完了のバランスを取る。
WebGPU Fundamentals

データ構造（具体）

Stroke（CPU）:

{
  id,
  points: [{x,y,t,pressure,tilt}, ...], // 原始点列
  toolParams: { width, profile, cap:'round'|'butt', join:'round'|'miter', textureId },
  pathApprox: { cubicBeziers: [...] } // オプションで近似
}


PathBuffer（GPU storage buffer）

各 point は 16~32 bytes（座標 + pressure + timestamp）

ExpandedMesh（GPU vertex/index buffer）

Compute が生成。各頂点は position + uv + extra attributes（for MSDF blending or texture mapping）

SDF / BrushTexture（GPU textures）

マルチチャネルSDF（MSDF）やブラシノイズテクスチャを用いる。

実装パイプライン：ステップバイステップ（実践向け）
ステップ A — PoC（概念実証、短期間で）

Pixi v8 + WebGPURenderer の最小サンプルを動かす。まず画面に四角描画できるところまで。
PixiJS

CPU 側で簡易ストローク→頂点列に変換（polyline の両側オフセットで即席アウトライン生成）。GPU に送って描画。これで一通りの pipeline が動く。

ここは compute を使わず CPU で行い、描画だけ GPU で行う（実装が速い）。

フラグメントで距離ベース AA を実装（alpha = smoothstep(threshold - w, threshold + w, distance)）。見た目が滑らかなら最初の目標達成。

ステップ B — 本格化（パフォーマンスと品質）

CPU -> GPU path uploads をバッファ化して一括送信（頻繁な小さな転送を避ける）。

Compute シェーダ実装：GPU-friendly stroke expansion のアルゴリズムを参考に実装（論文参照）。これで CPU 負荷を大幅に削減し、大きなパスも高速処理可。
arXiv

MSDF / SDF を使った AA：角の鋭さを維持するなら MSDF（多チャネル SDF）を使う。msdfgen 等でプリプロセスするか、ストローク用にオンザフライで生成する。
GitHub
Red Blob Games

Brushテクスチャ合成：ベースのベクターストロークに、テクスチャを乗せる（ループ描画やアルファ合成）して自然な筆致を出す。

API デザイン例（MainController 側）
// MainController (API)
main.createStroke(points, toolParams) // -> returns strokeId
main.updateStroke(strokeId, newPoints)
main.finalizeStroke(strokeId) // pushes to GPU path buffer
main.undo(), main.redo()
main.setLayer(layerId), main.setTool('pen'|'eraser'|'vector-pen')


GPU サイドは内部 API：

gpu.uploadPathBatch(pathsArray) → writes to storage buffer

gpu.computeExpandPaths(pathBuffer, outMeshBuffers) → dispatch compute

gpu.renderMeshes(meshBuffers, renderTarget)

120Hz 向け最適化・注意点

フレーム時間：120Hz → 8.33ms/frame。GPU と CPU の合計処理をこの中に入れるのは厳しい。戦略：

毎フレーム必須作業を最小化（pointer sampling → 軽量バッファ更新のみ）。

非同期 compute：ストロークの展開を非同期（別コマンドエンキュー）にして、ユーザーが描き続ける間は「暫定表示（GPU による即時簡易展開）」を行い、背後で高品質展開を行う。

ローカル補間（predictive smoothing）：入力が来るたびにすべて再展開せず、差分だけ処理。

GPU バッファの double/triple buffering と fence を適切に使い、GPU/CPU の同期待ちを避ける。
WebGPU Fundamentals

メモリ管理：大量ストロークでバッファが肥大化するので、LIFO スナップショット + 差分ログで undo を実装（フルテクスチャスナップは限定的に）。

WebGPU のサポート状況：デスクトップ Chrome / Edge 等では比較的対応が進んでいるが、ユーザ環境を想定して WebGL2 フォールバックを用意。Pixi v8 は両方を扱える。
PixiJS
PixiJS

AA（アンチエイリアス）具体案（高品質）

Compute→Outline→FilledTriangles + Fragment SDF AA（推奨）

正確で角がシャープ。パフォーマンスは高い（GPU 並列）。論文ベースの実装が参考になる。
arXiv

MSDF テクニック（文字・形状に強い）

事前生成の MSDF テクスチャを使うと解像度非依存でシャープな輪郭が得られる。だが、ストローク用にオンザフライ生成はコスト高。
GitHub

Shader smoothstep on alpha（簡易）

既存の Graphics を使う都合で最短実装。重さは中程度。

実装リスクと回避策

WebGPU 対応率：一部ユーザーのブラウザでは WebGPU が無い。→ Pixi の WebGL フォールバック路線で対応。
PixiJS

Compute アルゴリズムの複雑さ：論文実装は高度。PoC 段階で CPU ベースの高速セグメンテーションを作ってから GPU 移行する。
arXiv

デバッグ難易度：GPU バッファやシェーダのバグは見つけにくい。まずは小さいデータで単独テスト（unit test）を多用。

参考論文・資源（必読）

GPU-friendly Stroke Expansion — Raph Levien et al.（論文：GPU 上でのストローク展開アルゴリズム、実装指針）。
arXiv

Ciallo: GPU-Accelerated Rendering of Vector Brush Strokes — Adobe 研究（ベクターブラシの GPU 技術）。
Adobe Research

PixiJS v8 WebGPURenderer ドキュメント（Pixi が WebGPU をサポート）。
PixiJS
PixiJS

SDF / MSDF 解説（Red Blob / msdfgen） — 角保持のある距離場技術。
Red Blob Games
GitHub

WebGPU 最適化ガイド — 実運用で 120Hz を狙う際の実践的注意。
WebGPU Fundamentals

すぐ始めるための「最短実装プラン」 （1〜2 週間で PoC）

Pixi v8 をプロジェクトに導入し、WebGPURenderer サンプルを動かす（HelloTriangle 相当）。
PixiJS

CPU 側でポイント列→クイックアウトライン（両側オフセット）を生成する実装をする。GPU へ頂点バッファを送り描画。

フラグメントで smoothstep AA を入れて見た目を改善。インタラクティブ性（遅延）を観察して最適化。

次フェーズで compute に移行（論文アルゴリズムを参照）、MSDF／ブラシテクスチャ合成を追加。

最後に（推奨）

現実的最短路線：まずは CPU→GPU（頂点バッファ）で動く PoC を作る。これで主要な UX とボトルネックが見える。

本命：PoC のプロファイルを見てから GPU compute 化（stroke expansion）へ移行。これで 120Hz 達成に現実味が出ます。
arXiv
WebGPU Fundamentals

もしよければ、次のどちらかをください：
A) 「まずは PoC 用の最小サンプル（Pixi v8 WebGPURenderer + CPU アウトライン → シェーダ AA）」の実装コードをそのまま作る、
B) 「論文ベースの compute シェーダ実装（GPU-friendly stroke expansion）を Pixi のパイプラインに組み込む」ための詳細設計＋擬似コード（compute shader の疑似実装含む）

